{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this short project I have tried to use a pretrained model from [transformers](https://huggingface.co/transformers/) library for text summarization. Dataset was taken from [kaggle](https://www.kaggle.com/Cornell-University/arxiv). It consists of meta data of the scientific papers from *arXiv*. Due to the limited computational resources I have used abstracts of scientific papers (instead of entire articles) as text to be summarized and titles of these papers as targets. Downloaded model was fine-tuned on the Google Colab and it is hosted on the [huggingface](https://huggingface.co/Tymoteusz/optics-abstracts-summarization). Fine-tuning was done according to this tutorial [github](https://github.com/huggingface/notebooks/blob/master/examples/summarization.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import re\n",
    "from datasets import list_datasets, load_dataset, load_metric\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have only chosen papers related to optics by the *category* field. To filter by this condition we can use *regex*. Then we can create a dataframe and split it for training and validation set. The most efficient way for fine-tuning a pretrained model from transformers library is to create a *dataset* object. It allows to manipulate the data without reading it into memory and it is cached automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = []\n",
    "titles = []\n",
    "i = 0\n",
    "with jsonlines.open('arxiv-metadata-oai-snapshot.json') as reader:\n",
    "        for obj in reader:\n",
    "            if re.search('optics', obj['categories']) is not None:\n",
    "                titles.append(obj['title'])\n",
    "                abstracts.append(obj['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'titles': titles, 'abstracts': abstracts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Convergence of the discrete dipole approximati...</td>\n",
       "      <td>We performed a rigorous theoretical converge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Convergence of the discrete dipole approximati...</td>\n",
       "      <td>We propose an extrapolation technique that a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The discrete dipole approximation for simulati...</td>\n",
       "      <td>In this manuscript we investigate the capabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The discrete dipole approximation: an overview...</td>\n",
       "      <td>We present a review of the discrete dipole a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some new experimental photonic flame effect fe...</td>\n",
       "      <td>The results of the spectral, energetical and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34057</th>\n",
       "      <td>Quantum non-demolition (QND) modulation of qua...</td>\n",
       "      <td>We propose an experiment where quantum inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34058</th>\n",
       "      <td>Nonclassical correlations of photon number and...</td>\n",
       "      <td>It is shown that the quantum jumps in the ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34059</th>\n",
       "      <td>Optical Holonomic Quantum Computer</td>\n",
       "      <td>In this paper the idea of holonomic quantum ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34060</th>\n",
       "      <td>Solutions to the Optical Cascading Equations</td>\n",
       "      <td>Group theoretical methods are used to study ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34061</th>\n",
       "      <td>Integrability of the higher-order nonlinear Sc...</td>\n",
       "      <td>Only the known integrable cases of the Kodam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34062 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  titles  \\\n",
       "0      Convergence of the discrete dipole approximati...   \n",
       "1      Convergence of the discrete dipole approximati...   \n",
       "2      The discrete dipole approximation for simulati...   \n",
       "3      The discrete dipole approximation: an overview...   \n",
       "4      Some new experimental photonic flame effect fe...   \n",
       "...                                                  ...   \n",
       "34057  Quantum non-demolition (QND) modulation of qua...   \n",
       "34058  Nonclassical correlations of photon number and...   \n",
       "34059                 Optical Holonomic Quantum Computer   \n",
       "34060       Solutions to the Optical Cascading Equations   \n",
       "34061  Integrability of the higher-order nonlinear Sc...   \n",
       "\n",
       "                                               abstracts  \n",
       "0        We performed a rigorous theoretical converge...  \n",
       "1        We propose an extrapolation technique that a...  \n",
       "2        In this manuscript we investigate the capabi...  \n",
       "3        We present a review of the discrete dipole a...  \n",
       "4        The results of the spectral, energetical and...  \n",
       "...                                                  ...  \n",
       "34057    We propose an experiment where quantum inter...  \n",
       "34058    It is shown that the quantum jumps in the ph...  \n",
       "34059    In this paper the idea of holonomic quantum ...  \n",
       "34060    Group theoretical methods are used to study ...  \n",
       "34061    Only the known integrable cases of the Kodam...  \n",
       "\n",
       "[34062 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  Computation and visualization of Casimir forces in arbitrary geometries:\n",
      "  non-monotonic lateral forces and failure of proximity-force approximations\n",
      "\n",
      "\n",
      "Abstract:    We present a method of computing Casimir forces for arbitrary geometries,\n",
      "with any desired accuracy, that can directly exploit the efficiency of standard\n",
      "numerical-electromagnetism techniques. Using the simplest possible\n",
      "finite-difference implementation of this approach, we obtain both agreement\n",
      "with past results for cylinder-plate geometries, and also present results for\n",
      "new geometries. In particular, we examine a piston-like problem involving two\n",
      "dielectric and metallic squares sliding between two metallic walls, in two and\n",
      "three dimensions, respectively, and demonstrate non-additive and non-monotonic\n",
      "changes in the force due to these lateral walls.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Title: ', df['titles'][35])\n",
    "print('\\n')\n",
    "print('Abstract: ', df['abstracts'][35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('df_train.csv', index=False)\n",
    "df_test.to_csv('df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1f5f109b43dbc7b4\n",
      "Reusing dataset csv (D:\\ML_projects\\summarization_project\\csv\\default-1f5f109b43dbc7b4\\0.0.0\\e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': 'df_train.csv', 'test': 'df_test.csv'},\n",
    "                      cache_dir='D:\\\\ML_projects\\\\summarization_project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['titles', 'abstracts'],\n",
       "        num_rows: 28952\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['titles', 'abstracts'],\n",
       "        num_rows: 5110\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can specify which kind of pretrained model to use and download the corresponding tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstracts and titles need some preparation before they can be tokenized. We can replace every non word string, non whitespace string and a new line character with a whitespace. There are some abstracts which contain citations but we leave them without cleaning as most of abstracts are composed of words only. Prepared titles and abstracrs are then tokenized. Sizes of the tokenized abstracts and titles are limited by the used model so anything longer is truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    examples['titles'] = [re.sub(r'[^\\w\\s]', ' ', title) for title in examples['titles']]\n",
    "    examples['titles'] = [re.sub('\\n', ' ', title) for title in examples['titles']]\n",
    "    \n",
    "    examples['abstracts'] = [re.sub(r'[^\\w\\s]', ' ', abstract) for abstract in examples['abstracts']]\n",
    "    examples['abstracts'] = [re.sub('\\n', ' ', abstract) for abstract in examples['abstracts']]\n",
    "    \n",
    "    inputs = [prefix + abstract for abstract in examples['abstracts']]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples['titles'], max_length=max_target_length, truncation=True)\n",
    "    \n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[21603, 10, 1266, 12472, 7, 11, 11110, 13, 3, 9, 1249, 14930, 6772, 16183, 1413, 1010, 14148, 2699, 16, 3, 9, 10851, 14286, 7013, 2175, 10030, 33, 2196, 438, 3, 9, 209, 3538, 2179, 4401, 1391, 3, 9, 743, 14569, 4005, 13, 8, 3911, 11638, 19, 2546, 57, 3, 9, 335, 3, 632, 13944, 4401, 28351, 483, 16, 8, 505, 3, 632, 2179, 4401, 9400, 13, 8, 23471, 515, 291, 5432, 6772, 16183, 100, 3, 25875, 7, 12, 3, 9, 26533, 30024, 13, 108, 51, 17871, 26, 9, 12778, 100, 19, 46, 455, 13, 20722, 2755, 145, 3150, 2196, 772, 21, 48, 607, 13, 1413, 1010, 14148, 1], [21603, 10, 16184, 6849, 12237, 33, 46, 359, 1464, 12, 1848, 1737, 28911, 11638, 7, 13, 5272, 31728, 11423, 611, 7450, 10498, 2434, 686, 12237, 103, 59, 995, 21, 2547, 6772, 6849, 3, 28561, 13, 315, 3, 5628, 4900, 3379, 24, 164, 36, 915, 16, 3, 9, 11638, 84, 6790, 70, 1120, 2176, 2020, 21, 26075, 1427, 19276, 306, 29610, 3381, 454, 21855, 2836, 947, 62, 4277, 3, 9, 6772, 6849, 7824, 24, 3629, 8, 6772, 6849, 7, 13, 66, 8, 29610, 7, 16, 3, 9, 454, 21855, 11638, 16, 3, 9, 712, 1861, 4773, 938, 11906, 8, 8181, 28931, 7, 28, 5790, 3, 9454, 53, 7, 44, 315, 12602, 7, 62, 11609, 8432, 29610, 6772, 6849, 7, 11, 3, 7576, 1313, 11, 3442, 3, 13398, 12, 19547, 32, 13089, 4900, 1809, 224, 38, 13468, 851, 20382, 38, 168, 101, 5970, 8, 5644, 13, 8, 7824, 190, 3, 9, 8449, 9753, 13, 8, 6772, 6849, 7, 13, 668, 29610, 7, 16, 3, 9, 28433, 620, 344, 944, 11, 9526, 3, 29, 51, 28, 95, 12, 17871, 26, 9, 3538, 11723, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[3188, 1999, 14286, 7013, 2175, 6772, 16183, 1413, 1010, 14148, 28, 17871, 26, 9, 12778, 26533, 30024, 1], [3, 7727, 8792, 120, 13803, 712, 2538, 6772, 6849, 3952, 53, 13, 19276, 306, 29610, 2836, 1]]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(dataset['train'][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the *map* function to preprocess both the train and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at D:\\ML_projects\\summarization_project\\csv\\default-1f5f109b43dbc7b4\\0.0.0\\e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23\\cache-54c2967b8b2c869e.arrow\n",
      "Loading cached processed dataset at D:\\ML_projects\\summarization_project\\csv\\default-1f5f109b43dbc7b4\\0.0.0\\e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23\\cache-03c7d3a8df480672.arrow\n"
     ]
    }
   ],
   "source": [
    "prep_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['abstracts', 'attention_mask', 'input_ids', 'labels', 'titles'],\n",
       "        num_rows: 28952\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['abstracts', 'attention_mask', 'input_ids', 'labels', 'titles'],\n",
       "        num_rows: 5110\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstracts': ['  Predictions and measurements of a multimode waveguide interferometer operating in a fibre coupled    dual mode   regime are reported  With a 1 32 micrometer source  a complete switching cycle of the output beam is produced by a 10 0 nanometer incremental change in the 8 0 micrometer width of the hollow planar mirror waveguide  This equates to a fringe spacing of   sim lambda  130   This is an order of magnitude smaller than previously reported results for this form of interferometer  ',\n",
       "  '  Wavefront sensors are an important tool to characterize coherent beams of extreme ultraviolet radiation  However  conventional Hartmann type sensors do not allow for independent wavefront characterization of different spectral components that may be present in a beam  which limits their applicability for intrinsically broadband high harmonic generation  HHG  sources  Here we introduce a wavefront sensor that measures the wavefronts of all the harmonics in a HHG beam in a single camera exposure  By replacing the mask apertures with transmission gratings at different orientations  we simultaneously detect harmonic wavefronts and spectra  and obtain sensitivity to spatiotemporal structure such as pulse front tilt as well  We demonstrate the capabilities of the sensor through a parallel measurement of the wavefronts of 9 harmonics in a wavelength range between 25 and 49 nm  with up to lambda 32 precision  '],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]],\n",
       " 'input_ids': [[21603,\n",
       "   10,\n",
       "   1266,\n",
       "   12472,\n",
       "   7,\n",
       "   11,\n",
       "   11110,\n",
       "   13,\n",
       "   3,\n",
       "   9,\n",
       "   1249,\n",
       "   14930,\n",
       "   6772,\n",
       "   16183,\n",
       "   1413,\n",
       "   1010,\n",
       "   14148,\n",
       "   2699,\n",
       "   16,\n",
       "   3,\n",
       "   9,\n",
       "   10851,\n",
       "   14286,\n",
       "   7013,\n",
       "   2175,\n",
       "   10030,\n",
       "   33,\n",
       "   2196,\n",
       "   438,\n",
       "   3,\n",
       "   9,\n",
       "   209,\n",
       "   3538,\n",
       "   2179,\n",
       "   4401,\n",
       "   1391,\n",
       "   3,\n",
       "   9,\n",
       "   743,\n",
       "   14569,\n",
       "   4005,\n",
       "   13,\n",
       "   8,\n",
       "   3911,\n",
       "   11638,\n",
       "   19,\n",
       "   2546,\n",
       "   57,\n",
       "   3,\n",
       "   9,\n",
       "   335,\n",
       "   3,\n",
       "   632,\n",
       "   13944,\n",
       "   4401,\n",
       "   28351,\n",
       "   483,\n",
       "   16,\n",
       "   8,\n",
       "   505,\n",
       "   3,\n",
       "   632,\n",
       "   2179,\n",
       "   4401,\n",
       "   9400,\n",
       "   13,\n",
       "   8,\n",
       "   23471,\n",
       "   515,\n",
       "   291,\n",
       "   5432,\n",
       "   6772,\n",
       "   16183,\n",
       "   100,\n",
       "   3,\n",
       "   25875,\n",
       "   7,\n",
       "   12,\n",
       "   3,\n",
       "   9,\n",
       "   26533,\n",
       "   30024,\n",
       "   13,\n",
       "   108,\n",
       "   51,\n",
       "   17871,\n",
       "   26,\n",
       "   9,\n",
       "   12778,\n",
       "   100,\n",
       "   19,\n",
       "   46,\n",
       "   455,\n",
       "   13,\n",
       "   20722,\n",
       "   2755,\n",
       "   145,\n",
       "   3150,\n",
       "   2196,\n",
       "   772,\n",
       "   21,\n",
       "   48,\n",
       "   607,\n",
       "   13,\n",
       "   1413,\n",
       "   1010,\n",
       "   14148,\n",
       "   1],\n",
       "  [21603,\n",
       "   10,\n",
       "   16184,\n",
       "   6849,\n",
       "   12237,\n",
       "   33,\n",
       "   46,\n",
       "   359,\n",
       "   1464,\n",
       "   12,\n",
       "   1848,\n",
       "   1737,\n",
       "   28911,\n",
       "   11638,\n",
       "   7,\n",
       "   13,\n",
       "   5272,\n",
       "   31728,\n",
       "   11423,\n",
       "   611,\n",
       "   7450,\n",
       "   10498,\n",
       "   2434,\n",
       "   686,\n",
       "   12237,\n",
       "   103,\n",
       "   59,\n",
       "   995,\n",
       "   21,\n",
       "   2547,\n",
       "   6772,\n",
       "   6849,\n",
       "   3,\n",
       "   28561,\n",
       "   13,\n",
       "   315,\n",
       "   3,\n",
       "   5628,\n",
       "   4900,\n",
       "   3379,\n",
       "   24,\n",
       "   164,\n",
       "   36,\n",
       "   915,\n",
       "   16,\n",
       "   3,\n",
       "   9,\n",
       "   11638,\n",
       "   84,\n",
       "   6790,\n",
       "   70,\n",
       "   1120,\n",
       "   2176,\n",
       "   2020,\n",
       "   21,\n",
       "   26075,\n",
       "   1427,\n",
       "   19276,\n",
       "   306,\n",
       "   29610,\n",
       "   3381,\n",
       "   454,\n",
       "   21855,\n",
       "   2836,\n",
       "   947,\n",
       "   62,\n",
       "   4277,\n",
       "   3,\n",
       "   9,\n",
       "   6772,\n",
       "   6849,\n",
       "   7824,\n",
       "   24,\n",
       "   3629,\n",
       "   8,\n",
       "   6772,\n",
       "   6849,\n",
       "   7,\n",
       "   13,\n",
       "   66,\n",
       "   8,\n",
       "   29610,\n",
       "   7,\n",
       "   16,\n",
       "   3,\n",
       "   9,\n",
       "   454,\n",
       "   21855,\n",
       "   11638,\n",
       "   16,\n",
       "   3,\n",
       "   9,\n",
       "   712,\n",
       "   1861,\n",
       "   4773,\n",
       "   938,\n",
       "   11906,\n",
       "   8,\n",
       "   8181,\n",
       "   28931,\n",
       "   7,\n",
       "   28,\n",
       "   5790,\n",
       "   3,\n",
       "   9454,\n",
       "   53,\n",
       "   7,\n",
       "   44,\n",
       "   315,\n",
       "   12602,\n",
       "   7,\n",
       "   62,\n",
       "   11609,\n",
       "   8432,\n",
       "   29610,\n",
       "   6772,\n",
       "   6849,\n",
       "   7,\n",
       "   11,\n",
       "   3,\n",
       "   7576,\n",
       "   1313,\n",
       "   11,\n",
       "   3442,\n",
       "   3,\n",
       "   13398,\n",
       "   12,\n",
       "   19547,\n",
       "   32,\n",
       "   13089,\n",
       "   4900,\n",
       "   1809,\n",
       "   224,\n",
       "   38,\n",
       "   13468,\n",
       "   851,\n",
       "   20382,\n",
       "   38,\n",
       "   168,\n",
       "   101,\n",
       "   5970,\n",
       "   8,\n",
       "   5644,\n",
       "   13,\n",
       "   8,\n",
       "   7824,\n",
       "   190,\n",
       "   3,\n",
       "   9,\n",
       "   8449,\n",
       "   9753,\n",
       "   13,\n",
       "   8,\n",
       "   6772,\n",
       "   6849,\n",
       "   7,\n",
       "   13,\n",
       "   668,\n",
       "   29610,\n",
       "   7,\n",
       "   16,\n",
       "   3,\n",
       "   9,\n",
       "   28433,\n",
       "   620,\n",
       "   344,\n",
       "   944,\n",
       "   11,\n",
       "   9526,\n",
       "   3,\n",
       "   29,\n",
       "   51,\n",
       "   28,\n",
       "   95,\n",
       "   12,\n",
       "   17871,\n",
       "   26,\n",
       "   9,\n",
       "   3538,\n",
       "   11723,\n",
       "   1]],\n",
       " 'labels': [[3188,\n",
       "   1999,\n",
       "   14286,\n",
       "   7013,\n",
       "   2175,\n",
       "   6772,\n",
       "   16183,\n",
       "   1413,\n",
       "   1010,\n",
       "   14148,\n",
       "   28,\n",
       "   17871,\n",
       "   26,\n",
       "   9,\n",
       "   12778,\n",
       "   26533,\n",
       "   30024,\n",
       "   1],\n",
       "  [3,\n",
       "   7727,\n",
       "   8792,\n",
       "   120,\n",
       "   13803,\n",
       "   712,\n",
       "   2538,\n",
       "   6772,\n",
       "   6849,\n",
       "   3952,\n",
       "   53,\n",
       "   13,\n",
       "   19276,\n",
       "   306,\n",
       "   29610,\n",
       "   2836,\n",
       "   1]],\n",
       " 'titles': ['Fibre coupled dual mode waveguide interferometer with   lambda   130   fringe spacing',\n",
       "  'Spectrally resolved single shot wavefront sensing of broadband   high harmonic sources']}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_dataset['train'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to load the pretrained model from a checkpoint and also load a metric which will be used for evaluation. Here we are using a *rouge* set of metrics which are explained there [article](https://towardsdatascience.com/the-ultimate-performance-metric-in-nlp-111df6c64460). In general they are measuring how good is the generated summarization with respect to the target summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metric(name: \"rouge\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}, usage: \"\"\"\n",
       "Calculates average rouge scores for a list of hypotheses and references\n",
       "Args:\n",
       "    predictions: list of predictions to score. Each predictions\n",
       "        should be a string with tokens separated by spaces.\n",
       "    references: list of reference for each prediction. Each\n",
       "        reference should be a string with tokens separated by spaces.\n",
       "    rouge_types: A list of rouge types to calculate.\n",
       "        Valid names:\n",
       "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
       "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
       "        `\"rougeLSum\"`: rougeLsum splits text using `\"\n",
       "\"`.\n",
       "        See details in https://github.com/huggingface/datasets/issues/617\n",
       "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
       "    use_agregator: Return aggregates if this is set to True\n",
       "Returns:\n",
       "    rouge1: rouge_1 (precision, recall, f1),\n",
       "    rouge2: rouge_2 (precision, recall, f1),\n",
       "    rougeL: rouge_l (precision, recall, f1),\n",
       "    rougeLsum: rouge_lsum (precision, recall, f1)\n",
       "Examples:\n",
       "\n",
       "    >>> rouge = datasets.load_metric('rouge')\n",
       "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
       "    >>> references = [\"hello there\", \"general kenobi\"]\n",
       "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
       "    >>> print(list(results.keys()))\n",
       "    ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
       "    >>> print(results[\"rouge1\"])\n",
       "    AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))\n",
       "    >>> print(results[\"rouge1\"].mid.fmeasure)\n",
       "    1.0\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training parameters were set according to the tutorial. The *compute_metrics* function was also taken directly from that notebook. *DataCollator* is used for padding the sequences to the maximum sequence length within a batch and not the entire dataset. Training was done for 10 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    'gdrive/My Drive/trained_models',\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=prep_dataset['train'],\n",
    "    eval_dataset=prep_dataset['test'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuned model can be easily saved and then pushed to the repo on the *huggingface*. Evaluation metrics after each epoch were not shown cause training was done on the Google Colab but we can use the downloaded model to evaluate it on the validation set. All *rouge* metrics display the **F1 score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('gdrive/My Drive/final_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_data = pickle.load(open('evaluation_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.0490682125091553,\n",
       " 'eval_rouge1': 42.9079,\n",
       " 'eval_rouge2': 22.6112,\n",
       " 'eval_rougeL': 38.1581,\n",
       " 'eval_rougeLsum': 38.1522,\n",
       " 'eval_gen_len': 15.7039,\n",
       " 'eval_runtime': 131.1091,\n",
       " 'eval_samples_per_second': 38.975,\n",
       " 'eval_steps_per_second': 2.441,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Tymoteusz/optics-abstracts-summarization\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Tymoteusz/optics-abstracts-summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate summarizations we have to preprocess input abstracts in the similar way as before with cleaning and tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_sample(abstract):\n",
    "    abstract = re.sub(r'[^\\w\\s]', ' ', abstract)\n",
    "    abstract = re.sub('\\n', ' ', abstract)\n",
    "    abstract = tokenizer.encode(abstract, truncation=True, return_tensors=\"pt\")\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_number = 170\n",
    "sample_prep = prep_sample(dataset['test'][abstract_number]['abstracts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2892,  5790,    16,    16, 10207,  5255,    15,  1162,  1202,  2532,\n",
       "           783,    19,  7157,     3, 12913,    57,     8,  3438,    13,     8,\n",
       "         20624,    52,  6645,  2479,    16,     8,  2768,   947,    34,    19,\n",
       "          2008, 13605,   120,    24,    16,     3,     9,     3, 12851,  1202,\n",
       "          2532,  6884,  1809,   659,  5790,    11, 13503,   729,    15,   485,\n",
       "            13,     8,     3, 12851,  3438,    33,     3, 29604,    57,     3,\n",
       "             9,   650, 13080,   973,   728,     8,  2769,    13, 13503,   729,\n",
       "            15,   485,    13,     8,  1202,  2532,  1809,    19,  8413,    57,\n",
       "             8, 26664,  5538,  5456,  8152,    16,  7475, 29393,    11,   251,\n",
       "             3,    35, 12395,    63,    37, 11775,  1693,  1267,    24,     8,\n",
       "          5790,    13,   659,    16,   224,   783,  5619, 13080,   120,    45,\n",
       "            70, 13503,   729,    15,   485,     8,    72,    19, 13503,   729,\n",
       "            15,  1162,     8,  1809,     8,    72,    19,     8,   659, 19751,\n",
       "           438,     8,   435, 13080,  1675,    34,    19,   487,    12,  9689,\n",
       "             8,  5790,    13,   659,    16,  6504,  1202,  2532,  5278,    37,\n",
       "           741,    54,    36,  1934,    21,     8,   810,    13, 21126,  1855,\n",
       "            16,  1973,     7,   437,     8,  1126,   485,    28,   659,    16,\n",
       "          1202,  2532,   783,    68,    92,    21,     8,  3867,    13, 24713,\n",
       "            53,  7500,    21,     8,     3,    35,  1313,  5341,    13,   659,\n",
       "            12,    36, 14286,    28,  1202, 10897,     9,   447,  1904,     1]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_0 = model.generate(sample_tokenized, max_length=50,\n",
    "                         num_beams=4, early_stopping=True,\n",
    "                        num_return_sequences=3)\n",
    "outputs_1 = model.generate(sample_tokenized, max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Light transmission in inhomogeneous photonic crystal structures',\n",
       " 'Light transmission in inhomogeneous photonic crystals',\n",
       " 'Light transmission in inhomogeneous photonic media']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs_0, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Light transmission in random photonic crystal structures']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs_1, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  Transmission of Light in Crystals with different homogeneity: Using\n",
      "  Shannon Index in Photonic Media\n",
      "\n",
      "\n",
      "Abstract:    Light transmission in inhomogeneous photonic media is strongly influenced by\n",
      "the distribution of the diffractive elements in the medium. Here it is shown\n",
      "theoretically that, in a pillar photonic crystal structure, light transmission\n",
      "and homogeneity of the pillar distribution are correlated by a simple linear\n",
      "law once the grade of homogeneity of the photonic structure is measured by the\n",
      "Shannon index, widely employed in statistics, ecology and information entropy.\n",
      "The statistical analysis shows that the transmission of light in such media\n",
      "depends linearly from their homogeneity: the more is homogeneous the structure,\n",
      "the more is the light transmitted. With the found linear relationship it is\n",
      "possible to predict the transmission of light in random photonic structures.\n",
      "The result can be useful for the study of electron transport in solids, since\n",
      "the similarity with light in photonic media, but also for the engineering of\n",
      "scattering layers for the entrapping of light to be coupled with photovoltaic\n",
      "devices.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Title: ', dataset['test'][abstract_number]['titles'])\n",
    "print('\\n')\n",
    "print('Abstract: ', dataset['test'][abstract_number]['abstracts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
